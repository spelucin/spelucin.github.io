---
title: "XPath Para el SEO: Gu√≠a completa y usos"
date: 2023-06-12T22:22:45.154Z
description: Aprende a usar XPath para extraer data de sitios web de manera sistem√°tica
summary: Gu√≠a para usar XPath para extraer data de sitios web de manera
  sistem√°tica y enriquecer tus fuentes de datos SEO.
showSummary: true
slug: xpath-seo
tags:
  - web scraping
  - xpath
  - xml
---
Extraer data de sitios web es una de las cosas a la que los SEOs nos enfrentamos todos los d√≠as. Pese a que esta tarea puede ser tan simple como copiar y pegar, hoy quiero mostrarles una manera m√°s sistem√°tica de ejecutarla usando el lenguaje de consultas XPath.

Al final de este post, comprender√°s c√≥mo usar XPath para encontrar y extraer data de cualquier sitio web y complementar las fuentes de datos que ya utilizas en tu d√≠a a d√≠a como SEO.

## ¬øQu√© es el lenguaje XPath?

En t√©rminos simples, XPath (XML Path Language) es un lenguaje de consulta que permite navegar y extraer el contenido de documentos HTML y XML. La principal raz√≥n por la que este lenguaje es importante es porque nos ayuda a extraer el contenido de una web de manera sistem√°tica y replicable, ahorr√°ndonos horas de trabajo manual. Adem√°s, es un lenguaje que se hace entender de manera r√°pida una vez se conoce la sintaxis.

### ¬øC√≥mo se relaciona XPath con el SEO?

Existen muchas tareas en el posicionamiento web que requieren extraer data de sitios web para analizarlos y sacar conclusiones de ellos. Ya sea nuestra propia web o la de los competidores, se hace aparente la necesidad de extraer esta informaci√≥n en orden.

Tomemos como ejemplo un comercio electr√≥nico. Podemos usar esta [p√°gina de producto de Lazy Oaf](https://www.lazyoaf.com/products/lazy-cat-jumper) como ejemplo para este ejercicio. La expresi√≥n XPath para extraer el nombre del producto ser√≠a:

```xquery
//*[@class="product-main__information"]/h1
```

Si evaluamos la expresi√≥n XPath usando la [extensi√≥n de Chrome XPath Helper](https://chrome.google.com/webstore/detail/xpath-helper/hgimnogjllphhhkhlmebbmlgjoejdpjl), observamos que nos devuelve el t√≠tulo del producto:

![Ejemplo de una expresi√≥n XPath evaluada en la web de Lazy Oaf](/img/xpath-helper-chrome.png)

Ahora, imagina aplicar esto a escala: tanto como para 100 o 200.000 p√°ginas, para m√°s de un elemento y alinear la data extra√≠da con otras fuentes de datos c√≥mo Google Search Console o Ahrefs.

Para sacarle el jugo a XPath, es importante tener un conocimiento s√≥lido de la sintaxis. As√≠, empezaremos a construir nuestras propias consultas y extraer lo que queramos de cualquier sitio web.

## Sintaxis del lenguaje XPath

### Estructura de nodos en HTML y XML

Antes de entender como extraer contenido usando XPath, es necesario comprender la estructura de los documentos XML y HTML. En el ejemplo de abajo, vemos un documento XML est√°ndar tomado de \[https://www.w3schools.com/xml/xpath_syntax.asp](la web de W3Schools).

```xml
<?xml version="1.0" encoding="UTF-8"?>

<bookstore>

<book>
  <title lang="en">Harry Potter</title>
  <price>29.99</price>
</book>

<book>
  <title lang="en">Learning XML</title>
  <price>39.95</price>
</book>

</bookstore>
```

De igual manera, tenemos un documento HTML con una estructura completa:

```html
<!DOCTYPE html>
<html>
    <head>
      <title>Mi p√°gina web</title>
      <link rel="canonical" href="https://miweb.com/pagina/" />
    </head>
    <body>
      <article>
        <h1 class="heading-general" id="fist-heading">My First Heading</h1>
        <p class="first-paragraph">My first paragraph.</p>
        <p class="second-paragraph">My first paragraph.</p>
      </article>
    </body>
</html>
```

Lo que tienen ambos formatos en com√∫n es que ambos poseen una estructura de √°rbol: un nodo (o etiqueta, en el caso de HTML) se ubica dentro de otro, formando un √°rbol de nodos. Existe una jerarqu√≠a entre nodos o etiquetas, de tal manera que la consulta XPath navega entre los nodos para ser resuelta.

Cada nodo tiene una serie de atributos. En el caso del archivo XML, podemos ver el atributo `lang` con el valor `en`, y en el caso del archivo HTML los atributos podr√≠an corresponder a las clases y a los ID.

*Nota: en HTML esta estructura en forma de √°rbol se llama Document Object Model (DOM). EL DOM es una de las piedras angulares de la internet ;).*

### Navegando a trav√©s de HTML y XML con XPath

#### Seleccionado los nodos

Ahora que entendemos c√≥mo funciona la estructura de √°rbol en HTML y XML, ya podemos empezar a navegarlos. Los tokens que nos ayudar√°n son:

| **Expresi√≥n**   | **Descripci√≥n**                                                                                                           | **Ejemplo** |
| --------------- | ------------------------------------------------------------------------------------------------------------------------- | ----------- |
| nodename        | Selecciona el nodo con el nombre "nodename".                                                                              | h1          |
| /               | Selecciona el nodo ra√≠z.                                                                                                  | /h1         |
| //              | Selecciona un nodo desde la ra√≠z del documento, sin importar donde est√©.                                                  | //article   |
| /nodename/child | Selecciona todos los elementos de nombre "child" que se encuentren debajo de "nodename", sin importar donde se encuentren | /div/h1     |
| //@atributo     | Selecciona todos los atributos llamados "atributo"                                                                        | /Ôªø/@href    |

En el ejemplo HTML, si quisi√©ramos seleccionar el nodo que corresponde al `h1`con la clase `heading-general`, tendr√≠amos que escribir la siguiente consulta:

```xquery
//h1[@class='heading-general']
```

Esto nos devolver√° (dependiendo de la aplicaci√≥n y de lo espec√≠fico que seamos), el HTML interno del elemento seleccionado, el texto interior o el valor del atributo.

#### Predicates

Los predicates de XPath sirven para encontrar un nodo espec√≠fico o un valor espec√≠fico dentro de un set de nodos. Aqu√≠ es donde la cosa se pone interesante, ya que con los predicates nos permiten construir consultas m√°s avanzadas y precisas. Los predicates m√°s √∫tiles son:

| Expresi√≥n                  | Descripci√≥n                                                                                |
| -------------------------- | ------------------------------------------------------------------------------------------ |
| //title\[@lang]            | Selecciona el primer elemento de libro que es hijo del elemento "librer√≠a"                 |
| //title\[@lang='en']       | Selecciona todos los elementos de t√≠tulo que tienen un atributo "lang" con un valor de "en |
| /bookstore/book\[1]        | Selecciona el primer elemento de libro que es hijo del elemento "bookstore"                |
| /bookstore/book\[last()]   | Selecciona el √∫ltimo elemento de libro que es hijo del elemento "bookstore".Ôªø              |
| /bookstore/book\[last()-1] | Selecciona el pen√∫ltimo elemento de libro que es hijo del elemento "bookstore              |

Existen algunos predicates m√°s, pero no los he dejado aqu√≠ porque no son muy √∫tiles con archivos HTML. Puedes ver la lista de predicates completos en la [p√°gina de W3Schools sobre la sintaxis de XPath](https://www.w3schools.com/xml/xpath_syntax.asp).

Ya nos estamos acercando m√°s a la consulta de ejemplo, en el que se extrae un nodo usando su clase CSS junto a las etiquetas que le corresponden ¬°Buen trabajo!

#### Funciones y wildcards

XPath tiene algunas funciones muy √∫tiles para procesar la data extra√≠da, as√≠ como tokens que sirven de wildcards. Los m√°s √∫tiles a nivel de extracci√≥n de data para SEO son:

##### Funciones

| Funci√≥n       | Descripci√≥n                                                                                                                           | Ejemplo                                              |
| ------------- | ------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------- |
| contains()    | Determina si la primera cadena de argumentos contiene la segunda cadena de argumentos y devuelve un valor booleano verdadero o falso. | //a\[contains(.,‚Äôclic aqu√≠‚Äô)]/@href                  |
| count()       | Cuenta el n√∫mero de nodos en un conjunto de nodos y devuelve un n√∫mero entero.                                                        | count(//h3)                                          |
| starts-with() | Comprueba si la primera cadena comienza con la segunda cadena y devuelve verdadero o falso.                                           | //meta\[starts-with(@property, ‚Äòog:title‚Äô)]/@content |

##### Wildcards

| Token | Descripci√≥n                                       | Ejemplo                     |
| ----- | ------------------------------------------------- | --------------------------- |
| \*    | Cualquier elemento. Funciona como comod√≠n general | //*\[@class="mi-clase"]     |
| @*    | Cualquier atributo.                               | //div\[@*]                  |
| \|    | Operador "O" (para usar m√°s de una expresi√≥n).    | (//a/text() \| //a/img/@alt) |

¬°Genial! Ya est√°s listo para armar tus propias consultas XPath y extraer data de la web üéäüéä.

## Usando XPath en Screaming Frog

Antes de terminar este post, quer√≠a mostrar como usar este conocimiento de expresiones XPath para aplicarlo a un caso real.

Screaming Frog es uno de los crawlers m√°s usados (si no el m√°s usado) de la industria SEO. Una de las mejores caracter√≠sticas que tiene es que se le puede usar como un scraper web, es decir, se puede extraer contenido de manera sistem√°tica con √©l. Para este ejemplo, extraeremos atributos del [sitio de Lazy Oaf](https://lazyoaf.com).

Para empezar a extraer informaci√≥n de manera personalizada, iremos a "Configuraci√≥n > Personalizado > Extracci√≥n personalizada". Se nos mostrar√° la siguiente ventana:

![Extracci√≥n personalizada en Screaming Frog](/img/screaming-frog-extraccion-personalizada.png)

En ella, haremos clic en "A√±adir". Nos aparecer√° una nueva fila en la parte central de la ventana:

* La primera casilla corresponde al nombre del extractor. Este nombre es el que tendr√° la fila dentro de la interfaz de Screaming Frog.
* El tipo de selector nos permite escoger si deseamos usar XPath, expresiones regulares o selectores de CSS. En este caso, lo dejaremos en XPath.
* En el siguiente campo colocaremos la expresi√≥n XPath que hemos creado. La "X" roja cambiar√° a un check verde si la expresi√≥n es v√°lida.
* En la √∫ltima, decidiremos el tipo de extractor:

  * "HTML interno" nos devuelve las etiquetas que est√°n dentro del elemento que se selecciona mediante XPath.
  * "Extraer texto" nos devuelve el texto crudo (sin HTML) que corresponde al elemento seleccionado.
  * "Extraer elemento HTML" nos dar√° la etiqueta completa, con todas sus clases, IDs y dem√°s atributos.
  * "Valor de funci√≥n" solo sirve si vas a usar una funci√≥n como las de arriba ;).

Volviendo al sitio web de Lazy Oaf, extraeremos todos los nombres de producto y precios que tienen sus p√°ginas de producto. Mi flujo preferido para escribir una consulta XPath es el de abrir las DevTools de Chrome y emplear el inspector con el mouse (Ctrl + Shift + C) para seleccionar el posible elemento a extraer.

![Consultando la estructura de la web de LazyOaf](/img/chrome-devtools-lazyoaf.com.png)

Una vez abierto, no solo basta con observar la etiqueta del elemento que queremos extraer, tambi√©n debemos observar las etiquetas que le rodean. Observamos que existe una etiqueta `<div>` con la clase `product-main__information`. Podemos emplear esta informaci√≥n de la siguiente manera para crear el XPath del elemento:

```xquery
//div[@class='product-main__information']/h1
```

Incluimos la etiqueta `<div>` en caso existan otros H1 en la p√°gina. Evaluando la expresi√≥n XPath, obtenemos:

![Obteniendo el t√≠tulo del producto mediante XPath en la p√°gina de Lazy oaf](/img/xpath-helper-lazy-oaf-title.png)

Para el precio, tomamos una ruta similar: buscamos entre las etiquetas de la p√°gina, armamos la expresi√≥n y la evaluamos con XPath Helper. La expresi√≥n que usaremos es:

```xquery
//div[@class="product-price__price-container"]/span
```

Al evaluar la expresi√≥n, esto nos devuelve:

![Obteniendo el precio del producto mediante XPath en la p√°gina de Lazy Oaf](/img/xpath-helper-lazy-oaf-price.png)

Ahora que tenemos dos expresiones XPath, las llevaremos a Screaming Frog usando la ventana de "Extracci√≥n personalizada". Una vez que tenemos ambos selectores configurados, podemos rastrear la web o su mapa de sitio. En mi caso, decid√≠ rastrear el sitemap de productos.

Una vez que empezamos a correr el crawl, la pesta√±a "Extracci√≥n Personalizada" se empezar√° a popular con la data que le acabamos de pedir mediante las consultas XPath.

![Data del sitio web de Screaming Frog extra√≠da con XPath](/img/screaming-frog-extraccion-personalizada-lazy-oaf.png)

Hemos logrado emplear el lenguaje de consultas XPath para extraer data de un sitio web, sin tener que gastar horas en trabajo manual.

## Lecturas adicionales

1. [XPath - MDN Web Docs](https://developer.mozilla.org/en-US/docs/Web/XPath)
2. [Expresiones Xpath para SEO - LaikaTeam](https://laikateam.com/blog/expresiones-xpath-seo/)
3. [An SEO's guide to XPath - Builtvisible](https://builtvisible.com/seo-guide-to-xpath/)
4. [XPath Tutorial - W3 Schools](https://www.w3schools.com/xml/xpath_intro.asp)